# 5CLOUD-data-platform-for-real-time-event-analysis

ğŸ“Œ Introduction

Ce projet a pour objectif de construire une plateforme de donnÃ©es temps rÃ©el capable de collecter, ingÃ©rer, traiter et visualiser des donnÃ©es provenant dâ€™une source ouverte.
Nous avons utilisÃ© les services Microsoft Azure (Synapse Analytics, Data Lake) ainsi que des outils locaux (Python, Jupyter Notebook) pour simuler le fonctionnement complet dâ€™une architecture cloud moderne.

La source choisie est lâ€™API gratuite Open-Meteo, qui fournit des donnÃ©es mÃ©tÃ©orologiques actualisÃ©es en continu.
Le pipeline mis en place permet de rÃ©cupÃ©rer les observations mÃ©tÃ©o (tempÃ©rature, vent), de les stocker dans Azure, de les transformer via Synapse, puis de les visualiser localement.

â¸»

ğŸ¯ Objectifs du projet

Le projet devait permettre de :
	â€¢	Collecter des donnÃ©es mÃ©tÃ©orologiques en temps rÃ©el via une API publique.
	â€¢	Stocker automatiquement ces donnÃ©es dans un stockage cloud Azure (Data Lake Gen2).
	â€¢	Traiter et transformer les donnÃ©es Ã  lâ€™aide dâ€™Azure Synapse Analytics.
	â€¢	Produire des visualisations analytiques depuis un notebook Python.
	â€¢	Simuler un pipeline de donnÃ©es complet, similaire Ã  une architecture utilisÃ©e en entreprise.

â¸»

ğŸ› ï¸ Architecture & Environnement Azure

Un compte Azure for Students a Ã©tÃ© utilisÃ© pour crÃ©er les ressources suivantes :
	â€¢	Synapse Analytics Workspace : syn-etgrealtime
	â€¢	Azure Data Lake Storage Gen2 : stetgrealtimeleo01
	â€¢	Conteneur de stockage : data/openmeteo
	â€¢	Connexion entre Synapse et le Data Lake pour lecture SQL via OPENROWSET.

Les fichiers JSON mÃ©tÃ©o collectÃ©s sont placÃ©s dans le dossier :
data/openmeteo/

â¸»

ğŸ“¥ Ã‰tape 1 â€“ Collecte des donnÃ©es (API Open-Meteo)

Nous avons sÃ©lectionnÃ© lâ€™API Open-Meteo comme source de donnÃ©es.
Lâ€™API permet de rÃ©cupÃ©rer :
	â€¢	la tempÃ©rature en Â°C
	â€¢	la vitesse du vent en km/h
	â€¢	lâ€™horodatage des mesures

En pratique, un script Python local interrogeait pÃ©riodiquement lâ€™API et enregistrait un fichier JSON sous la forme :

meteo_YYYYMMDD_HHMM.json

Chaque fichier simule une ingestion horaire, comme si Azure Data Factory effectuait un pipeline automatique.

Ces fichiers ont ensuite Ã©tÃ© envoyÃ©s manuellement dans Azure Data Lake, reproduisant le rÃ©sultat dâ€™un pipeline automatisÃ© tout en Ã©vitant les coÃ»ts Azure.

â¸»

â˜ï¸ Ã‰tape 2 â€“ Ingestion dans Azure Data Lake

Le Data Lake comporte un dossier openmeteo dans lequel tous les fichiers JSON ont Ã©tÃ© copiÃ©s.

Azure Synapse a Ã©tÃ© reliÃ© Ã  ce stockage grÃ¢ce Ã  une linked service, ce qui permet :
	â€¢	la lecture directe des fichiers JSON dans SQL
	â€¢	le traitement Ã  la volÃ©e sans besoin de base SQL dÃ©diÃ©e

Chaque fichier JSON reprÃ©sente un Ã©chantillon horaire, permettant ainsi une analyse rÃ©elle de sÃ©ries temporelles.

â¸»

ğŸ§® Ã‰tape 3 â€“ Traitement et transformation via Azure Synapse Analytics

Lâ€™ingestion terminÃ©e, la transformation a Ã©tÃ© effectuÃ©e grÃ¢ce au moteur SQL Serverless de Synapse.

Les actions rÃ©alisÃ©es :
	1.	CrÃ©ation dâ€™une source de donnÃ©es externe pointant vers le Data Lake.
	2.	DÃ©finition dâ€™un format de fichier JSON.
	3.	Lecture dynamique des fichiers JSON grÃ¢ce Ã  OPENROWSET.
	4.	Extraction des champs utiles :
	â€¢	obs_time
	â€¢	temperature
	â€¢	windspeed

Une vue logique nommÃ©e dbo.vw_openmeteo a Ã©tÃ© crÃ©Ã©e pour exposer ces donnÃ©es nettoyÃ©es et uniformisÃ©es.

Synapse a ensuite permis de gÃ©nÃ©rer un graphique intÃ©grÃ© afin de valider la cohÃ©rence des donnÃ©es avant analyse.

â¸»

ğŸ“Š Ã‰tape 4 â€“ Visualisation locale avec Jupyter Notebook

Les fichiers JSON ont Ã©tÃ© tÃ©lÃ©chargÃ©s localement dans un dossier :

Meteo_json/

Ã€ partir dâ€™un notebook Python, nous avons :
	â€¢	chargÃ© tous les fichiers JSON
	â€¢	converti les donnÃ©es en DataFrame (pandas)
	â€¢	nettoyÃ© les sÃ©ries temporelles
	â€¢	gÃ©nÃ©rÃ© 3 graphiques via matplotlib :

Figure 7 â€“ Ã‰volution de la tempÃ©rature

Titre sous lâ€™image :
Ã‰volution horaire de la tempÃ©rature mesurÃ©e Ã  Paris.

Figure 8 â€“ Variation de la vitesse du vent

Titre sous lâ€™image :
Variation de la vitesse du vent sur la mÃªme pÃ©riode.

Figure 9 â€“ CorrÃ©lation tempÃ©rature / vent

Titre sous lâ€™image :
ReprÃ©sentation combinÃ©e tempÃ©rature et vitesse du vent.

Ces figures servent de dashboard analytique local.
Elles reproduisent lâ€™Ã©tape finale qui aurait Ã©tÃ© rÃ©alisÃ©e dans Power BI dans un scÃ©nario 100% cloud.

â¸»

ğŸ“Œ Conclusion

Ce projet dÃ©montre la construction dâ€™une plateforme de donnÃ©es en temps rÃ©el basÃ©e sur Azure, tout en utilisant des alternatives locales compatibles avec les contraintes Ã©tudiantes.

Nous avons rÃ©ussi Ã  :
	â€¢	Collecter des donnÃ©es mÃ©tÃ©orologiques rÃ©elles.
	â€¢	Simuler une ingestion automatisÃ©e vers un Data Lake Azure.
	â€¢	Traiter dynamiquement les donnÃ©es via Synapse SQL Serverless.
	â€¢	Produire des visualisations analytiques permettant dâ€™interprÃ©ter les tendances.

Cette architecture reproduit fidÃ¨lement le fonctionnement dâ€™un pipeline professionnel tout en restant simple, Ã©conomique et pÃ©dagogique.
